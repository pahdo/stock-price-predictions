Using TensorFlow backend.
Traceback (most recent call last):
  File "tf-idf-30-day-returns.py", line 2, in <module>
    from Doc2VecUtils import SentimentDocument
  File "/home/jovyan/text-analytics-for-accountancy/Doc2Vec/Doc2VecUtils.py", line 2, in <module>
    import gensim.utils
  File "/home/jovyan/.local/lib/python3.6/site-packages/gensim/__init__.py", line 6, in <module>
    from gensim import parsing, matutils, interfaces, corpora, models, similarities, summarization
  File "/home/jovyan/.local/lib/python3.6/site-packages/gensim/models/__init__.py", line 7, in <module>
    from .coherencemodel import CoherenceModel
  File "/home/jovyan/.local/lib/python3.6/site-packages/gensim/models/coherencemodel.py", line 30, in <module>
    from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet
  File "/home/jovyan/.local/lib/python3.6/site-packages/gensim/models/wrappers/__init__.py", line 8, in <module>
    from .fasttext import FastText
  File "/home/jovyan/.local/lib/python3.6/site-packages/gensim/models/wrappers/fasttext.py", line 38, in <module>
    from gensim.models.keyedvectors import KeyedVectors, Vocab
  File "/home/jovyan/.local/lib/python3.6/site-packages/gensim/models/keyedvectors.py", line 82, in <module>
    from keras.layers import Embedding
  File "/opt/conda/lib/python3.6/site-packages/keras/__init__.py", line 3, in <module>
    from . import utils
  File "/opt/conda/lib/python3.6/site-packages/keras/utils/__init__.py", line 6, in <module>
    from . import conv_utils
  File "/opt/conda/lib/python3.6/site-packages/keras/utils/conv_utils.py", line 3, in <module>
    from .. import backend as K
  File "/opt/conda/lib/python3.6/site-packages/keras/backend/__init__.py", line 83, in <module>
    from .tensorflow_backend import *
  File "/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 1, in <module>
    import tensorflow as tf
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import *
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/__init__.py", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/framework_lib.py", line 98, in <module>
    from tensorflow.python.framework.subscribe import subscribe
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/subscribe.py", line 26, in <module>
    from tensorflow.python.ops import variables
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py", line 26, in <module>
    from tensorflow.python.ops import control_flow_ops
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 67, in <module>
    from tensorflow.python.ops import gen_data_flow_ops
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py", line 5585, in <module>
    _op_def_lib = _InitOpDefLibrary()
  File "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py", line 2852, in _InitOpDefLibrary
    _text_format.Merge(_InitOpDefLibrary.op_list_ascii, op_list)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 525, in Merge
    descriptor_pool=descriptor_pool)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 579, in MergeLines
    return parser.MergeLines(lines, message)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 612, in MergeLines
    self._ParseOrMerge(lines, message)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 627, in _ParseOrMerge
    self._MergeField(tokenizer, message)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 727, in _MergeField
    merger(tokenizer, message, field)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 815, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 727, in _MergeField
    merger(tokenizer, message, field)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 815, in _MergeMessageField
    self._MergeField(tokenizer, sub_message)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 727, in _MergeField
    merger(tokenizer, message, field)
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 769, in _MergeMessageField
    tokenizer.Consume('{')
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 1078, in Consume
    if not self.TryConsume(token):
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 1065, in TryConsume
    self.NextToken()
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 1308, in NextToken
    self._SkipWhitespace()
  File "/opt/conda/lib/python3.6/site-packages/google/protobuf/text_format.py", line 1048, in _SkipWhitespace
    self._PopLine()
KeyboardInterrupt
Starting...
Reading through corpus and building word embeddings...
read line 0
read line 25000
read line 50000
read line 75000
read line 100000
read line 125000
read line 150000
read line 175000
read line 200000
read line 225000
read line 250000
read line 275000
read line 300000
read line 325000
read line 350000
read line 375000
read line 400000
read line 425000
read line 450000
read line 475000
Using TensorFlow backend.
Traceback (most recent call last):
  File "tf-idf-30-day-returns.py", line 50, in <module>
    embedded = vectorizer.fit_transform(corpus)
  File "/home/jovyan/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py", line 1381, in fit_transform
    X = super(TfidfVectorizer, self).fit_transform(raw_documents)
  File "/home/jovyan/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py", line 869, in fit_transform
    self.fixed_vocabulary_)
  File "/home/jovyan/.local/lib/python3.6/site-packages/sklearn/feature_extraction/text.py", line 790, in _count_vocab
    for doc in raw_documents:
  File "tf-idf-30-day-returns.py", line 11, in read_corpus
    for line_no, line in enumerate(file):
OSError: [Errno 12] Cannot allocate memory
