string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9])}
Traceback (most recent call last):
  File "tf_idf_v2.py", line 127, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 110, in run_experiment
    grid_search = RandomizedSearchCV(pipe, param_grid=param_dict, cv=ts_cv, n_jobs=24, pre_dispatch='n_jobs')
TypeError: __init__() got an unexpected keyword argument 'param_grid'
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 128, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 115, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 639, in fit
    cv.split(X, y, groups)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 789, in __call__
    self.retrieve()
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 699, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 385, in _handle_tasks
    put(task)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 393, in _send_bytes
    header = struct.pack("!i", n)
struct.error: 'i' format requires -2147483648 <= number <= 2147483647
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 117, in run_experiment
    dataset['X'] = joblib.load('dataset_dump.pkl', mmap_mode='r+')
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 578, in load
    obj = _unpickle(fobj, filename, mmap_mode)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 508, in _unpickle
    obj = unpickler.load()
  File "/usr/lib/python3.5/pickle.py", line 1039, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 341, in load_build
    self.stack.append(array_wrapper.read(self))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 182, in read
    array = self.read_mmap(unpickler)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 160, in read_mmap
    offset=offset)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/backports.py", line 23, in make_memmap
    shape=shape, order=order)
  File "/usr/lib/python3/dist-packages/numpy/core/memmap.py", line 260, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
OSError: [Errno 24] Too many open files
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 117, in run_experiment
    dataset['X'] = joblib.load('dataset_dump.pkl', mmap_mode='r')
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 578, in load
    obj = _unpickle(fobj, filename, mmap_mode)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 508, in _unpickle
    obj = unpickler.load()
  File "/usr/lib/python3.5/pickle.py", line 1039, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 341, in load_build
    self.stack.append(array_wrapper.read(self))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 182, in read
    array = self.read_mmap(unpickler)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 160, in read_mmap
    offset=offset)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/backports.py", line 23, in make_memmap
    shape=shape, order=order)
  File "/usr/lib/python3/dist-packages/numpy/core/memmap.py", line 260, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
OSError: [Errno 24] Too many open files
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 117, in run_experiment
    dataset['X'] = joblib.load('dataset_dump.pkl', mmap_mode='c')
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 578, in load
    obj = _unpickle(fobj, filename, mmap_mode)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 508, in _unpickle
    obj = unpickler.load()
  File "/usr/lib/python3.5/pickle.py", line 1039, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 341, in load_build
    self.stack.append(array_wrapper.read(self))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 182, in read
    array = self.read_mmap(unpickler)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 160, in read_mmap
    offset=offset)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/backports.py", line 23, in make_memmap
    shape=shape, order=order)
  File "/usr/lib/python3/dist-packages/numpy/core/memmap.py", line 260, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
OSError: [Errno 24] Too many open files
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 117, in run_experiment
    dataset['X'] = joblib.load('dataset_dump.pkl', mmap_mode='c')
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 578, in load
    obj = _unpickle(fobj, filename, mmap_mode)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 508, in _unpickle
    obj = unpickler.load()
  File "/usr/lib/python3.5/pickle.py", line 1039, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 341, in load_build
    self.stack.append(array_wrapper.read(self))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 182, in read
    array = self.read_mmap(unpickler)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 160, in read_mmap
    offset=offset)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/backports.py", line 23, in make_memmap
    shape=shape, order=order)
  File "/usr/lib/python3/dist-packages/numpy/core/memmap.py", line 260, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
OSError: [Errno 24] Too many open files
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 119, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 639, in fit
    cv.split(X, y, groups)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 789, in __call__
    self.retrieve()
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 699, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 385, in _handle_tasks
    put(task)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 393, in _send_bytes
    header = struct.pack("!i", n)
struct.error: 'i' format requires -2147483648 <= number <= 2147483647
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__min_child_weight': array([6, 7]), 'clf__max_depth': array([7]), 'clf__subsample': array([ 0.7]), 'clf__colsample_bytree': array([ 0.7])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 119, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 618, in fit
    candidate_params = list(self._get_param_iterator())
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 250, in __iter__
    "GridSearchCV." % (grid_size, self.n_iter))
ValueError: The total space of parameters 2 is smaller than n_iter=10. For exhaustive searches, use GridSearchCV.
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__colsample_bytree': array([ 0.7,  0.8]), 'clf__subsample': array([ 0.7,  0.8]), 'clf__max_depth': array([6, 7]), 'clf__min_child_weight': array([6, 7])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 119, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 639, in fit
    cv.split(X, y, groups)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 789, in __call__
    self.retrieve()
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 699, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 385, in _handle_tasks
    put(task)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 393, in _send_bytes
    header = struct.pack("!i", n)
struct.error: 'i' format requires -2147483648 <= number <= 2147483647
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__min_child_weight': array([6, 7]), 'clf__subsample': array([ 0.7,  0.8]), 'clf__max_depth': array([6, 7]), 'clf__colsample_bytree': array([ 0.7,  0.8])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 117, in run_experiment
    dataset['X'] = joblib.load('dataset_dump.pkl', mmap_mode='c')
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 578, in load
    obj = _unpickle(fobj, filename, mmap_mode)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 508, in _unpickle
    obj = unpickler.load()
  File "/usr/lib/python3.5/pickle.py", line 1039, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 341, in load_build
    self.stack.append(array_wrapper.read(self))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 182, in read
    array = self.read_mmap(unpickler)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 160, in read_mmap
    offset=offset)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/backports.py", line 23, in make_memmap
    shape=shape, order=order)
  File "/usr/lib/python3/dist-packages/numpy/core/memmap.py", line 260, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
OSError: [Errno 24] Too many open files
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__subsample': array([ 0.7,  0.8]), 'clf__max_depth': array([6, 7]), 'clf__min_child_weight': array([6, 7]), 'clf__colsample_bytree': array([ 0.7,  0.8])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 132, in <module>
    main()
  File "tf_idf_v2.py", line 91, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 117, in run_experiment
    dataset['X'] = joblib.load('dataset_dump.pkl', mmap_mode='c')
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 578, in load
    obj = _unpickle(fobj, filename, mmap_mode)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 508, in _unpickle
    obj = unpickler.load()
  File "/usr/lib/python3.5/pickle.py", line 1039, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 341, in load_build
    self.stack.append(array_wrapper.read(self))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 182, in read
    array = self.read_mmap(unpickler)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/numpy_pickle.py", line 160, in read_mmap
    offset=offset)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/backports.py", line 23, in make_memmap
    shape=shape, order=order)
  File "/usr/lib/python3/dist-packages/numpy/core/memmap.py", line 260, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
OSError: [Errno 24] Too many open files
Traceback (most recent call last):
  File "tf_idf_v2.py", line 133, in <module>
    main()
  File "tf_idf_v2.py", line 88, in main
    dataset = read_dataset_dictionary(label_horizon=label_horizon, subset=subset)
  File "tf_idf_v2.py", line 46, in read_dataset_dictionary
    X = np.array(dtype=object)
TypeError: Required argument 'object' (pos 1) not found
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 0
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__min_child_weight': array([6, 7]), 'clf__colsample_bytree': array([ 0.7,  0.8]), 'clf__subsample': array([ 0.7,  0.8]), 'clf__max_depth': array([6, 7])}
0
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 133, in <module>
    main()
  File "tf_idf_v2.py", line 92, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 120, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 592, in fit
    cv = check_cv(self.cv, y, classifier=is_classifier(estimator))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py", line 1915, in check_cv
    return _CVIterableWrapper(cv)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py", line 1817, in __init__
    self.cv = list(cv)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py", line 767, in split
    n_samples))
ValueError: Cannot have number of folds =11 greater than the number of samples: 0.
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__max_depth': array([6, 7]), 'clf__colsample_bytree': array([ 0.7,  0.8]), 'clf__subsample': array([ 0.7,  0.8]), 'clf__min_child_weight': array([6, 7])}
66273
66273
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 133, in <module>
    main()
  File "tf_idf_v2.py", line 92, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 120, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 639, in fit
    cv.split(X, y, groups)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 749, in __call__
    n_jobs = self._initialize_backend()
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 547, in _initialize_backend
    **self._backend_args)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py", line 317, in configure
    self._pool = MemmapingPool(n_jobs, **backend_args)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 600, in __init__
    super(MemmapingPool, self).__init__(**poolargs)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 420, in __init__
    super(PicklingPool, self).__init__(**poolargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 168, in __init__
    self._repopulate_pool()
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 233, in _repopulate_pool
    w.start()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/usr/lib/python3.5/multiprocessing/context.py", line 267, in _Popen
    return Popen(process_obj)
  File "/usr/lib/python3.5/multiprocessing/popen_fork.py", line 20, in __init__
    self._launch(process_obj)
  File "/usr/lib/python3.5/multiprocessing/popen_fork.py", line 67, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
Traceback (most recent call last):
  File "tf_idf_v2.py", line 133, in <module>
    main()
  File "tf_idf_v2.py", line 92, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 120, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 639, in fit
    cv.split(X, y, groups)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 749, in __call__
    n_jobs = self._initialize_backend()
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 547, in _initialize_backend
    **self._backend_args)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py", line 317, in configure
    self._pool = MemmapingPool(n_jobs, **backend_args)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 600, in __init__
    super(MemmapingPool, self).__init__(**poolargs)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 420, in __init__
    super(PicklingPool, self).__init__(**poolargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 168, in __init__
    self._repopulate_pool()
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 233, in _repopulate_pool
    w.start()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 105, in start
    self._popen = self._Popen(self)
  File "/usr/lib/python3.5/multiprocessing/context.py", line 267, in _Popen
    return Popen(process_obj)
  File "/usr/lib/python3.5/multiprocessing/popen_fork.py", line 20, in __init__
    self._launch(process_obj)
  File "/usr/lib/python3.5/multiprocessing/popen_fork.py", line 67, in _launch
    self.pid = os.fork()
OSError: [Errno 12] Cannot allocate memory
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-8:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-15:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-1:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-14:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-18:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9])}
66273
66273
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-12:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-21:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
Process ForkServerPoolWorker-6:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 125, in worker
    put((job, i, result))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 130, in worker
    put((job, i, (False, wrapped)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 386, in put
    return send(obj)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 372, in send
    self._writer.send_bytes(buffer.getvalue())
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.5/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 178, in main
    _serve_one(s, listener, alive_r, handler)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 215, in _serve_one
    write_unsigned(child_w, code)
  File "/usr/lib/python3.5/multiprocessing/forkserver.py", line 234, in write_unsigned
    nbytes = os.write(fd, msg)
BrokenPipeError: [Errno 32] Broken pipe
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('price_history', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))])), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=None, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9]), 'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
