string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('union', FeatureUnion(n_jobs=1,
       transformer_list=[('linguistic', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='corpus')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=...tory', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))]))],
       transformer_weights={'price_history': 1.0, 'linguistic': 1.0})), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=1, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__max_depth': array([3, 4, 5, 6, 7, 8, 9]), 'clf__subsample': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'clf__colsample_bytree': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'union__linguistic__tfidf__sublinear_tf': [True], 'union__linguistic__tfidf__min_df': array([ 0.1,  0.2,  0.3]), 'union__linguistic__tfidf__max_df': array([ 0.5,  0.6,  0.7,  0.8,  0.9]), 'union__linguistic__nmf__n_components': array([ 50, 100, 150, 200, 250, 300]), 'clf__min_child_weight': array([3, 4, 5, 6, 7, 8, 9])}
66273
66273
Top 3 lines
#1: joblib/numpy_pickle.py:108: 3521528.5 KiB
    array = pickle.load(unpickler.file_handle)
#2: python3.5/pickle.py:1039: 8.3 KiB
    dispatch[key[0]](self)
#3: tf_idf_v2.py:30: 4.7 KiB
    path, prices, labels = path_prices_labels.split(';')
112 other: 64.1 KiB
Total allocated size: 3521605.5 KiB
Traceback (most recent call last):
  File "tf_idf_v2.py", line 146, in <module>
    main()
  File "tf_idf_v2.py", line 100, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 134, in run_experiment
    grid_search.fit(dataset['X'], dataset['labels']) 
  File "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py", line 639, in fit
    cv.split(X, y, groups)))
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 789, in __call__
    self.retrieve()
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py", line 699, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 608, in get
    raise self._value
  File "/usr/lib/python3.5/multiprocessing/pool.py", line 385, in _handle_tasks
    put(task)
  File "/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/pool.py", line 371, in send
    CustomizablePickler(buffer, self._reducers).dump(obj)
MemoryError
Traceback (most recent call last):
  File "tf_idf_v2.py", line 15, in <module>
    import my_estimators
  File "/home/ubuntu/notebooks/text-analytics-for-accountancy/doc2vec/my_estimators.py", line 91
    """
      ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "tf_idf_v2.py", line 15, in <module>
    import my_estimators
  File "/home/ubuntu/notebooks/text-analytics-for-accountancy/doc2vec/my_estimators.py", line 96
    '''
      ^
SyntaxError: invalid syntax
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('union', FeatureUnion(n_jobs=1,
       transformer_list=[('linguistic', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='corpus')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=...tory', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))]))],
       transformer_weights={'price_history': 1.0, 'linguistic': 1.0})), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=1, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__colsample_bytree': array([ 0.7]), 'clf__max_depth': array([6]), 'union__linguistic__nmf__n_components': array([200]), 'union__linguistic__tfidf__sublinear_tf': [True], 'union__linguistic__tfidf__max_df': array([ 0.7]), 'clf__subsample': array([ 0.7]), 'union__linguistic__tfidf__min_df': array([ 0.2]), 'clf__min_child_weight': array([6])}
Traceback (most recent call last):
  File "tf_idf_v2.py", line 147, in <module>
    main()
  File "tf_idf_v2.py", line 100, in main
    run_experiment(estimators, param_grid, pickle_path, dataset)
  File "tf_idf_v2.py", line 128, in run_experiment
    grid_search = GridSearchCV(pipe, param_distributions=param_dict, cv=ts_cv)
TypeError: __init__() got an unexpected keyword argument 'param_distributions'
/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20
  DeprecationWarning)
string price: 1.8591981136572546
string price: 1.2885263121198216
string price: 1.0773845281177161
string price: 1.121257804323449
string price: 8.965153219298495
string price: 1.2990684024571935
string price: 9.064884734018875
string price: 2.006564011672051
string price: 2.3335508561398757
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 2.3359429007602555
string price: 1.2591215623738339
string price: 1.2787003960170784
string price: 6.266887232538808
string price: 1.5002095829715556
dataset_size = 66273
labels len = 66273
experiment starting with estimators=[('union', FeatureUnion(n_jobs=1,
       transformer_list=[('linguistic', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='corpus')), ('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=...tory', Pipeline(memory=None,
     steps=[('selector', CustomDictVectorizer(key='price_history'))]))],
       transformer_weights={'price_history': 1.0, 'linguistic': 1.0})), ('clf', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,
       n_jobs=1, nthread=1, objective='multi:softmax', random_state=0,
       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
       silent=True, subsample=1))] param_dict={'clf__min_child_weight': array([6]), 'clf__colsample_bytree': array([ 0.7]), 'clf__max_depth': array([6]), 'union__linguistic__tfidf__min_df': array([ 0.2]), 'union__linguistic__nmf__n_components': array([200]), 'clf__subsample': array([ 0.7]), 'union__linguistic__tfidf__sublinear_tf': [True], 'union__linguistic__tfidf__max_df': array([ 0.7])}
66273
66273
Top 3 lines
#1: joblib/numpy_pickle.py:108: 3521528.4 KiB
    array = pickle.load(unpickler.file_handle)
#2: python3.5/pickle.py:1039: 8.3 KiB
    dispatch[key[0]](self)
#3: tf_idf_v2.py:30: 4.7 KiB
    path, prices, labels = path_prices_labels.split(';')
113 other: 64.5 KiB
Total allocated size: 3521606.0 KiB
Total running time: 23849.692086696625
{'split7_test_score': array([ 0.41799469]), 'split1_test_score': array([ 0.39060425]), 'param_union__linguistic__nmf__n_components': masked_array(data = [200],
             mask = [False],
       fill_value = ?)
, 'param_clf__min_child_weight': masked_array(data = [6],
             mask = [False],
       fill_value = ?)
, 'split5_test_score': array([ 0.41284861]), 'mean_score_time': array([ 60.09506333]), 'split1_train_score': array([ 0.98308037]), 'split2_train_score': array([ 0.9511089]), 'split3_train_score': array([ 0.92221531]), 'split9_test_score': array([ 0.40869854]), 'param_union__linguistic__tfidf__min_df': masked_array(data = [0.20000000000000001],
             mask = [False],
       fill_value = ?)
, 'rank_test_score': array([1], dtype=int32), 'split0_train_score': array([ 0.99469584]), 'split3_test_score': array([ 0.38927623]), 'std_score_time': array([ 10.9247049]), 'param_union__linguistic__tfidf__sublinear_tf': masked_array(data = [True],
             mask = [False],
       fill_value = ?)
, 'split8_train_score': array([ 0.77733518]), 'split7_train_score': array([ 0.79878011]), 'mean_train_score': array([ 0.87496568]), 'params': [{'clf__min_child_weight': 6, 'clf__colsample_bytree': 0.69999999999999996, 'clf__subsample': 0.69999999999999996, 'union__linguistic__tfidf__sublinear_tf': True, 'clf__max_depth': 6, 'union__linguistic__tfidf__min_df': 0.20000000000000001, 'union__linguistic__nmf__n_components': 200, 'union__linguistic__tfidf__max_df': 0.69999999999999996}], 'split5_train_score': array([ 0.85168589]), 'param_clf__subsample': masked_array(data = [0.69999999999999996],
             mask = [False],
       fill_value = ?)
, 'mean_fit_time': array([ 1690.73850904]), 'split4_test_score': array([ 0.41484064]), 'mean_test_score': array([ 0.40444887]), 'split2_test_score': array([ 0.40156042]), 'split8_test_score': array([ 0.40205843]), 'split4_train_score': array([ 0.89292708]), 'std_test_score': array([ 0.01168031]), 'split6_test_score': array([ 0.41982072]), 'std_train_score': array([ 0.08156646]), 'param_clf__colsample_bytree': masked_array(data = [0.69999999999999996],
             mask = [False],
       fill_value = ?)
, 'param_union__linguistic__tfidf__max_df': masked_array(data = [0.69999999999999996],
             mask = [False],
       fill_value = ?)
, 'split0_test_score': array([ 0.38678619]), 'param_clf__max_depth': masked_array(data = [6],
             mask = [False],
       fill_value = ?)
, 'split9_train_score': array([ 0.76183837]), 'std_fit_time': array([ 983.85814165]), 'split6_train_score': array([ 0.81598976])}
[mean: 0.40445, std: 0.01168, params: {'clf__min_child_weight': 6, 'clf__colsample_bytree': 0.69999999999999996, 'clf__subsample': 0.69999999999999996, 'union__linguistic__tfidf__sublinear_tf': True, 'clf__max_depth': 6, 'union__linguistic__tfidf__min_df': 0.20000000000000001, 'union__linguistic__nmf__n_components': 200, 'union__linguistic__tfidf__max_df': 0.69999999999999996}]
{'clf__min_child_weight': 6, 'clf__colsample_bytree': 0.69999999999999996, 'clf__subsample': 0.69999999999999996, 'union__linguistic__tfidf__sublinear_tf': True, 'clf__max_depth': 6, 'union__linguistic__tfidf__min_df': 0.20000000000000001, 'union__linguistic__nmf__n_components': 200, 'union__linguistic__tfidf__max_df': 0.69999999999999996}
0.404448871182
